工作日志
======
###date:2014-04-26     
work：   

* 对数据做了简单统计，先数据odps平台的sql操作。    
* 将用户八月份买的产品再推荐一遍，推荐的品牌个数有  1271388个。

####result
P:3.96%,R:1.78%,F_1:2.45    
用户真实购买的品牌长度大约有2828426个。


###date：2013-04-27
work：
看完了odps-sql文档。

给用户推荐之前购买过的物品，按购买品牌的次数最多推荐5个。推荐的物品个数有800多万。

###date :2013-04-28
work:看完了odps-xlab文档,不过对xlab的脚本语言这块不太理解。 

推荐最近一个月内点击超过3次的物品，推荐品牌个数为7,289,821个 
####result
P：2.40%,R:6.17%,F_1：3.45%
好像上面的sql结果并没有去重...（不需要去重）

用户购买行为中，购买次数超过两次的物品有2,315,232个。   
最近一个月收藏的物品有1,262622

###date：2013-04-29  

推荐最近20天，用户**点击**次数超过5次的品牌。推荐的品牌个数为：3,317,859
####result
P:3.47%,R:4.06,F_1:3.74%    

没有进行去噪处理。

###date:2013-04-30

用户购买行为中，购买次数超过两次的物品有2,315,232个。  
###result
P:3.36%,R:2.74%,F_1:3.02%

###date:2013-05-01

用户购买行为中，去噪操作：删除没有过购买行为的用户．

推荐最近19天内用户点击超过３次的物品，推荐的品牌个数约450万．

####result
P:2.91%,R:4.66%,F_1:3.58%.

###date:2013-05-02

向用户推荐用户购买大于等于３次的品牌，推荐品牌书大约９０万   
向用户推荐那些有过购买行为的用户在最后１９天对品牌点击大于等于５次的品牌，推荐品牌大约２２６万.    
将两个列表融合，没有进行去重处理．       
####results
P:3.17%,R:4.17%,F_1:3.93%

###date:2013-05-03
对上面的策略进行去重操作．去重后推荐的品牌有将近３００万个．
####result
P:3.91%,R:4.17%,F_1:4.04%

###date:2013-05-04
加强了一下策略，主要是推荐最近１０天内点击超过３次的品牌．去重后总共推荐的品牌数为３１１万．
####result
P:3.92%,R4.31%,F_1:4.11%.

###date:2013-05-05
是这么认为的，对于那些购买过的品牌，如果在最近一段时间点击过，便进行推荐．同时加上购买次数超过３次的品牌，形成推荐列表
当时发现推荐列表过长，接近五百万．当时的理解是最近购买的行为会产生推荐列表过长，于是便限制为查看至少一个月之前购买过的品牌在最近二十天点击过则进行推荐，这样推荐列表的长度将下来了．总共推荐了１５５万左右．  
P:4.24%,R:2.33%,F_1:3.01%   

###date:2013-05-06
推荐最近１０天内点击超过４次的商品，已经购买大于等于３次的商品，总过推荐２４０万左右.
####result
P:4.48%,R:3.76%,F_1:4.09%.

##date:2013-05-07
推荐最近７天内点击超过３次的商品，已经购买超过两次的物品．总推荐商品３７０万． 
###result
P:3.58%,R:4.78%,F_1:4.10%.

##date:2013-05-08
逻辑回归实现．

###result
P:2.50,R:2.45%,F_1:2.48%.   

###分析
效果很差，初始以为是逻辑回归迭代次数过少(２５)导致未学习到最优解．但是将迭代次数增加到1000次之后发现也没有很大的差别．所以应该不是迭代次数造成的原因．
不知道是不是选取特征粒度太细的原因？
